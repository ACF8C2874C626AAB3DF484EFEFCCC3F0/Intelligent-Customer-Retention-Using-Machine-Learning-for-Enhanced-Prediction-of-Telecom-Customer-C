# -*- coding: utf-8 -*-
"""siranjeev.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m-biJmSUDDMNeQyFTC0DXJRPbX6Wgzuh
"""

import pandas as pd

import numpy as np

import pickle

import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import seaborn as sns

import sklearn

from sklearn.preprocessing import OneHotEncoder

from sklearn.linear_model import LogisticRegression

from sklearn.tree import DecisionTreeClassifier

from sklearn.ensemble import RandomForestClassifier

from sklearn.neighbors import KNeighborsClassifier

from sklearn.svm import SVC

from sklearn.model_selection import RandomizedSearchCV

from sklearn import linear_model
from sklearn.model_selection import train_test_split

!pip install "data"

import imblearn

from imblearn.over_sampling import SMOTE

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

df = pd.read_csv("/content/Telco-Customer-Churn.csv")

df.head()

df.info()

df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')

df.isnull().any()

df["TotalCharges"].fillna(df["TotalCharges"].median() , inplace =True)

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df["gender"] = le.fit_transform(df["gender"])

df["Partner"] = le.fit_transform(df[ "Partner"])

df["Dependents"] = le.fit_transform(df[ "Dependents"])

df["PhoneService"] = le.fit_transform(df["PhoneService"])

df['MultipleLines'] = le.fit_transform(df['MultipleLines'])

df["InternetService"] = le.fit_transform(df["InternetService"])

df["OnlineSecurity"] = le.fit_transform(df["OnlineSecurity"])

df["OnlineBackup"] = le.fit_transform(df["OnlineBackup"])

df["DeviceProtection"] = le.fit_transform(df["DeviceProtection"])

df["TechSupport"] = le.fit_transform(df["TechSupport"])

df["StreamingTV"] = le.fit_transform(df["StreamingTV"])

df["StreamingMovies"] = le.fit_transform(df[ "StreamingMovies"])

df["Contract"] = le.fit_transform(df["Contract"])

df["PaperlessBilling"] = le.fit_transform(df[ "PaperlessBilling"])

df[ "PaymentMethod"] = le.fit_transform(df[ "PaymentMethod"])

df["Churn"] = le.fit_transform(df["Churn"])

df.head()

x = df.iloc[:,0:19].values
y = df.iloc[:,19:20].values

x

y

"""# New Section"""

from sklearn.preprocessing import OneHotEncoder
one = OneHotEncoder()

a= one.fit_transform(x[:,6:7]).toarray() 

b= one.fit_transform(x[:,7:8]).toarray()

c= one.fit_transform(x[:,8:9]).toarray()

d= one.fit_transform(x[:,9:10]).toarray()

e= one.fit_transform(x[:,10:11]).toarray()

f= one.fit_transform(x[:,11:12]).toarray() 

g= one.fit_transform(x[:,12:13]).toarray()

h= one.fit_transform(x[:,13:14]).toarray()

i= one.fit_transform(x[:,14:15]).toarray()

j= one. fit_transform(x[:,16:17]).toarray()

x=np.delete(x,[6,7,8,9,10,11,12,13,14,16],axis=1)

x=np.concatenate((a,b,c,d,e,f,g,h,i,j,x),axis=1)

from imblearn.over_sampling import SMOTE

smt = SMOTE()

from sklearn.datasets import make_classification
X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,
                           n_redundant=0, n_repeated=0, n_classes=3,
                           n_clusters_per_class=1,
                           weights=[0.01, 0.05, 0.94],
                           class_sep=0.8, random_state=0)
from imblearn.over_sampling import RandomOverSampler
smt = RandomOverSampler(random_state=0)
X_resampled, y_resampled = smt.fit_resample(X, y)

X_resampled

y_resampled

x.shape, X_resampled.shape

y.shape, y_resampled.shape

df.describe()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.distplot(df["tenure"])
plt.subplot(1,2,2)
sns.distplot(df["MonthlyCharges"])

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.countplot(df["gender"])
plt.subplot(1,2,2)
sns.countplot(df["Dependents"])

sns.barplot(x='Churn', y="MonthlyCharges",data=df)

sns.heatmap(df.corr(), annot=True)

sns.pairplot(data=df, markers=["^","v"], palette="inferno")

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size = 0.2,random_state = 0)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

X_train.shape

def logreg(X_train,X_test,y_train,y_test): 
  
  lr = LogisticRegression(random_state=0)

  lr.fit(X_train,y_train)

  y_lr_tr = lr.predict(X_train)

  print(accuracy_score(y_lr_tr,y_train))

  yPred_lr = lr.predict(X_test)

  print(accuracy_score(yPred_lr,y_test))

  print("***Logistic Regression***")

  print("Confusion Matrix")

  print(confusion_matrix(y_test,yPred_lr))

  print("classification Report")

  print(classification_report(y_test,yPred_lr))

logreg(X_train,X_test,y_train,y_test)

def decisionTree(X_train,X_test,y_train,y_test):

    dtc = DecisionTreeClassifier(criterion="entropy",random_state=0)

    dtc.fit(X_train,y_train)

    y_dt_tr = dtc.predict(X_train)

    print(accuracy_score (y_dt_tr,y_train))
    
    yPred_dt = dtc.predict(X_test)

    print(accuracy_score(yPred_dt,y_test))

    print("***Decision Tree***") 
    
    print("Confusion_Matrix")

    print(confusion_matrix(y_test,yPred_dt))

    print("Classification Report")
    
    print(classification_report(y_test,yPred_dt))

decisionTree(X_train,X_test,y_train,y_test)

def RandomForest(X_train,X_test,y_train,y_test):
    rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
    rf.fit(X_train,y_train)  
    y_rf_tr = rf.predict(X_train)
    print(accuracy_score(y_rf_tr,y_train))
    yPred_rf=rf.predict(X_test)
    print(accuracy_score(yPred_rf,y_test))
    print("******Random Forest******")
    print("Confusion Matrix")
    print(confusion_matrix(y_test,yPred_rf))
    print("classification Report")
    print(classification_report(y_test,yPred_rf))

RandomForest(X_train,X_test,y_train,y_test)

def KNN(X_train,X_test,y_train,y_test):

    knn = KNeighborsClassifier() 
    
    knn.fit(X_train,y_train)

    y_knn_tr = knn.predict(X_train)

    print(accuracy_score(y_knn_tr,y_train))
    
    yPred_knn = knn.predict(X_test)

    print(accuracy_score(yPred_knn,y_test))

    print("***KNN***")

    print("Confusion_Matrix")

    print(confusion_matrix(y_test,yPred_knn))

    print("Classification Report")

    print(classification_report(y_test,yPred_knn))

KNN(X_train,X_test,y_train,y_test)

def svm(X_train,X_test,y_train,y_test):

    svm = SVC(kernel = "linear")

    svm.fit(X_train,y_train)

    y_svm_tr = svm.predict(X_train)

    print(accuracy_score(y_svm_tr,y_train)) 
    
    yPred_svm = svm.predict(X_test)

    print(accuracy_score(yPred_svm,y_test))
    
    print("***Support vector Machine***")

    print("Confusion_Matrix")

    print(confusion_matrix(y_test,yPred_svm))

    print("Classification Report")

    print(classification_report(y_test,yPred_svm))

svm(X_train,X_test,y_train,y_test)

!pip3 install Tensorflow

import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization
from keras.models import Sequential
from keras.optimizers import Adam

classifier = Sequential()

classifier.add(Dense(units=30, activation='relu', input_dim=40))

classifier.add(Dense(units=30, activation='relu'))

classifier.add(Dense(units=1, activation='sigmoid'))

classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense
import numpy as np

X_train = np.random.rand(1000,128,128,3)
y_train = np.random.rand(1000,2)
X_test = np.random.rand(200,128,128,3)
y_test = np.random.rand(200,2)

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(2, activation='sigmoid'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test,y_test))

ann_pred = model.predict(X_test)
ann_pred = (ann_pred>0.5)
ann_pred

